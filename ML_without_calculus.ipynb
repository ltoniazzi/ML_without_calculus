{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "fbc85660-3b51-45ac-a96e-19d8277f664a",
            "metadata": {},
            "source": [
                "# Supervised learning (without calculus!)\n",
                "This tutorial wants to show the (possibly) most naive way to train the most naive neural network on the [MNIST database](https://en.wikipedia.org/wiki/MNIST_database). For our model we only need to known matrix multiplication, for loops. Importantly, no knowledge of calculus  (gradient descent) is required and coding syntax is explained in detail. The reader expect to:\n",
                "\n",
                "- present key ideas in machine learning in simple setting\n",
                "- be impressed by power of simple matrix multiplication\n",
                "- build intuition for issues such as overfitting.\n",
                "- have plenty of extensions of the model to experiment.\n",
                "\n",
                "(This tutorial was originally made as a concrete application of linear algebra course at Otago University.)\n",
                "\n",
                "We first import some basic packages along with the training/testing and test dataset and we reduce the size of the training dataset. (Note that tensorflow is only used to import the data.)",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "3b5fff4f-e815-4349-b7b4-a9b9c5d89c51",
            "metadata": {},
            "outputs": [],
            "source": [
                "# We import the packages that we will use\n",
                "import matplotlib.pyplot as plt\n",
                "import tensorflow as tf\n",
                "import numpy as np\n",
                "from numpy.linalg import norm as Euclid_norm\n",
                "from time import time\n",
                "mnist = tf.keras.datasets.mnist\n",
                "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
                "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
                "size_of_training_set = 200\n",
                "x_train, y_train = x_train[:size_of_training_set], y_train[:size_of_training_set]",
            ],
        },
        {
            "cell_type": "markdown",
            "id": "aff319bb-d2d0-40d9-942b-320bc0c90515",
            "metadata": {},
            "source": [
                "## Data visualisation\n",
                "\n",
                'Our aim is to "train" a "machine"  capable of recognising the ten digits $\\{0,1,2,3,4,5,6,7,8,9\\}$ when hand-written. It is natural to show the machine a bunch of these digits and then to train it to choose correctly by rewarding the machine  when correct, and penalising  it otherwise (much like humans do). Once trained we send the machine into the unkown territory of the testing data set, and see how well it performs. Lukily, images are matrices (tabular arrays) where each position represent a pixel and the value of this entry is the color (and machines love matrices). Let\'s see this.',
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "88c9de0d-7462-494d-8a3f-eb6b982581a4",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": ["<Figure size 720x288 with 5 Axes>"],
                    },
                    "metadata": {"needs_background": "light"},
                    "output_type": "display_data",
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "To see the first image in matrix notation type x_train[0] in a cell and run it. \n"
                    ],
                },
            ],
            "source": [
                "fig, ax = plt.subplots(1,5,figsize=(10,4))\n",
                "fig.suptitle('.jpg files as 28x28 matrices with the respective labels', fontsize=15)\n",
                "for j in range(5):\n",
                "    ax[j].imshow(x_train[j:j+1][0])\n",
                "    ax[j].set_title(f'Label: {y_train[j]}');\n",
                "plt.show();\n",
                'print("To see the first image in matrix notation type x_train[0] in a cell and run it. ");',
            ],
        },
        {
            "cell_type": "markdown",
            "id": "d080c703-9032-4d63-a643-3c1be19815c8",
            "metadata": {},
            "source": [
                "## The neural network\n",
                "\n",
                "So an image as a $28\\times 28$ matrix, or equivalenty a $28^2\\times 1$ vector/matrix, obtained by flattening it (stack all rows in one line). For each image/vector the machine needs to return a number between 0 and 9 (according to what the image is understood to be). What is the easiest (reasonable) way to obtain ten evaluations out of a $28^2\\times 1$ vector $x$. Of course it is matrix multiplication by a $10\\times 28^2$ matrix `W`. The matrix `W` is called the weights matrix (it weights the 10 different options) and our model follows the simple\n",
                "\n",
                "\n",
                "**Decision rule**: `x` is the digit equal to the index of the biggest entry in `W`.\n",
                "\n",
                "\n",
                "For example if `Wx`  $ = [0,0,0,1,0,3,-\\pi, 7,100]^T$, then the machine tells us that `x` is the picture of a 9. That simple.\n",
                "\n",
                "\n",
                "Training = finding a good `W`. What's good? It's up to us to decide.  An option is to tell the machine that $W x$ needs to have a very high third entry if the label of $x$ is 2, this is the same as asking that \n",
                "\n",
                "- $\\|W x-y \\|_2$ is small,\n",
                "- $y = [0,0,C,0,0,0,0,0,0,0]$,\n",
                "- $C>0$ is very big and \n",
                "\n",
                "where $\\|$    `x`  $ \\|_2=(x_0^2+...+x^2_9)^{\\frac12}$ is the 10-$d$ Euclidean norm. We require this to be samll for all images in the traning set by requiring that the loss function \n",
                "$$\n",
                "L(W)= \\frac1n\\sum_{i=1}^n\\|Wx_i - y_i\\|_2\n",
                "$$\n",
                "is small, where $\\{(x_i,y_i)\\}_{i=1}^n$ are the pairs of images with their vector label and $n$ is `size_of_training_set`. Mathematically, a `W` that minimises `L(W)` is a solution to the problem $\\arg\\min_W L(W)$.\n",
                "\n",
                "\n",
                "How do we train this model? With a **trivialised gradient descent alghoritym**: \n",
                "\n",
                "Initialize at the entry `(i,j)=(0,0)`,  then \n",
                "\n",
                "1. Take the current `W` and create a copy `W_temp` that equals `W` apart from `W_temp[i,j] = W[i,j]+1`,\n",
                "2. if `L(W_temp) < L(W)` make `W_temp` the new `W`.\n",
                "3. Fix a new entry `(i,j)`  to move  horizontally in the $10\\times 28^2$ matrix `W` (skipping lines once at the last column and staring back from `(0,0)` once all entries have been visited)\n",
                "4. start back at 1.",
            ],
        },
        {
            "cell_type": "markdown",
            "id": "a7bd4d12-a8c2-442f-80a7-fe181046906f",
            "metadata": {},
            "source": [
                "## Model construction\n",
                "\n",
                "We first flatten all images and construct labeld vectors in `y_label`.",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "1dc64f9d-28ef-4b5c-813d-4ef74623c036",
            "metadata": {},
            "outputs": [],
            "source": [
                "#Flatten images in training set\n",
                "x_train = x_train.reshape(x_train.shape[0],28*28)\n",
                "x_test = x_test.reshape(x_test.shape[0],28**2)\n",
                "#Create 10x1 vectors with a 1-entry corresponding the respective\n",
                "#image label\n",
                "y_label = np.zeros((y_train.shape[0], 10))\n",
                "for i in range(y_train.shape[0]):\n",
                "    y_label[i,y_train[i]] = 1",
            ],
        },
        {
            "cell_type": "markdown",
            "id": "cafa0501-a26d-4d2f-a1bc-acacf5f63000",
            "metadata": {},
            "source": [
                "The following is the class cotaining our model. It performs three main tasks:\n",
                "\n",
                "1. `nl = NL()`: the model is created and named `nl`, and the size of each image input vector is set to 28*28, the output vector size to 10, the weight matrix `W` is initialised to a $10\\times28*28$  matrix where each entry is a 0, the number of times we run through all the entries of `W` in our gradiant descent (in `self.steps`).\n",
                "\n",
                "2. `nl.fit(x_train,y_label)`: this is the trivialized gradient descent, check the description of the steps!\n",
                "\n",
                "3. `nl.predict(x_test):` the decision making process. The `nl` computes the matrix product `W@x` with the current `W` for each image `x` in `x_test` and returns its decisions, i.e. the index of the  biggest entry in `W@x`.\n",
                "\n",
                "The remaining two functions simply compute the average correct predicitons of `nl` and allow to return the current weights matrix `W`. ",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "c9acb45f-7c9c-4499-88d6-5e25264c7398",
            "metadata": {},
            "outputs": [],
            "source": [
                "class NL:\n",
                "    def __init__(self):\n",
                "        self.size_in = 28*28\n",
                "        self.size_out = 10\n",
                "        self.steps = 10\n",
                "        self.weights = np.zeros((self.size_out, self.size_in))\n",
                "        \n",
                "    def fit(self,x_train,y_label):\n",
                '        """Train the neural network by performing the trivialized \n',
                "        gradient descent.\n",
                '        """\n',
                "        t_start = time() #Time at start of training\n",
                "        steps = self.steps*(self.size_in*self.size_out) #Number of iteration of the descent algo\n",
                "        W = self.weights #The current weights\n",
                "        h, C = 2., 10**6. #Set the learning step h and the big constant C to scale y_label\n",
                "        y_label = C*y_label\n",
                "        \n",
                "        #Algorythm starts here:\n",
                "        for i in range(steps): #Steps 3 and 4 happen here\n",
                "            \n",
                "            #Step 1: make a copy of W\n",
                "            W_temp = W.copy()\n",
                "            #Change the current entry of W_temp by h\n",
                "            j = i % (self.size_in*self.size_out -1)\n",
                "            W_temp.reshape(np.prod(W_temp.shape))[j] =  W_temp.reshape(np.prod(W_temp.shape))[j] + h\n",
                "            \n",
                "            #Step 2: Create a matrix contaning all vectors Wx - y\n",
                "            Wx_minus_y = np.ones(x_train.shape[0]*10).reshape(x_train.shape[0],10)\n",
                "            for  m in range(x_train.shape[0]):\n",
                "                Wx_minus_y[m] = W@x_train[m]- y_label[m]\n",
                "            #and create a matrix contaning all vectors W_temp x - y    \n",
                "            W_temp_x_minus_y = np.ones(x_train.shape[0]*10).reshape(x_train.shape[0],10)\n",
                "            for  m in range(x_train.shape[0]):\n",
                "                W_temp_x_minus_y[m] = W_temp@x_train[m] - y_label[m]\n",
                "            #and then compute the loss under the current and temporary weight matrices\n",
                "            Loss_W = Euclid_norm(Wx_minus_y,axis=0).mean()\n",
                "            Loss_W_temp = Euclid_norm(W_temp_x_minus_y,axis=0).mean()\n",
                "            #and decide whether we descend with W_temp\n",
                "            if Loss_W_temp < Loss_W:\n",
                "                W = W_temp\n",
                "        \n",
                "        t_end = time() #Time at end of training\n",
                "        self.weights = W  # The training has finished and the last W is set to be the model weight matrix\n",
                '        print("Training time:", np.round(t_end-t_start,2),"s")\n',
                "    \n",
                "    def predict(self,x_test):\n",
                '        """Predict the digit in each image x in x_test by returning\n',
                "        the position where W@x is the highest.\n",
                '        """\n',
                "        y_pred = np.ones(x_test.shape[0])\n",
                "        for i in range(x_test.shape[0]):\n",
                "            y_pred[i] = np.where(self.weights@x_test[i]\n",
                "                        == np.max(self.weights@x_test[i]))[0][0]\n",
                "        return y_pred\n",
                "\n",
                "    def return_weights(self):\n",
                "        return self.weights\n",
                "    \n",
                "    def accuracy(self,y_test,y_pred):\n",
                "        return len(np.where((y_pred - y_test) == 0.)[0])/len(y_test)",
            ],
        },
        {
            "cell_type": "markdown",
            "id": "9fd2f315-c0e6-4cf6-b346-d787b7dff525",
            "metadata": {},
            "source": [
                "So initialise/instantiate the model and check its predicitons before training, which are of course goiong to be pretty bad and expected to be around 10% accuracy (why?)."
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "aaaadc4b-c02f-47fd-ba8d-f8fd5cd84d41",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Probability of correct prediciton before training:\n",
                        " 0.098\n",
                    ],
                }
            ],
            "source": [
                "nl = NL()\n",
                "#Compute prediciton accuracy without training\n",
                "y_pred = nl.predict(x_test)\n",
                'print("Probability of correct prediciton before training:\\n", nl.accuracy(y_pred,y_test))',
            ],
        },
        {
            "cell_type": "markdown",
            "id": "b467f9a9-62e7-4a15-961b-685c872f0e6a",
            "metadata": {},
            "source": [
                "Finally, we are ready to train (or fit) the model. So lets feed to `nl` the training images with the respective labels and let do its homework."
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "1b704b1f-190e-45bc-8c9b-4b98fa9d44b9",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": ["Training time: 218.1 s\n"],
                }
            ],
            "source": ["nl.fit(x_train,y_label)"],
        },
        {
            "cell_type": "markdown",
            "id": "75dcb753-3cc9-4764-a5bf-92152c8d42c2",
            "metadata": {},
            "source": [
                "Now that the model is trained (i.e. a better `W` has been found), lets check its predicitons."
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "c40b4bfb-1aa8-4bca-b8ba-04a55210c349",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Probability of correct prediciton after training\n",
                        "\n",
                        "- on traning set: 0.815\n",
                        "\n",
                        "- on test set: 0.5591\n",
                    ],
                }
            ],
            "source": [
                "y_pred_in_sample = nl.predict(x_train)\n",
                'print("Probability of correct prediciton after training\\n\\n- on traning set:",\n',
                "      nl.accuracy(y_pred_in_sample,y_train))\n",
                "y_pred_out_of_sample = nl.predict(x_test)\n",
                'print("\\n- on test set:",\n',
                "      nl.accuracy(y_pred_out_of_sample,y_test))",
            ],
        },
        {
            "cell_type": "markdown",
            "id": "88a85e9a-c463-45bc-9a82-f37e09c80ac6",
            "metadata": {},
            "source": [
                "## Conclusion \n",
                "\n",
                "So we trained our machine to recognise digits at a 55% accuracy with rather trivial mathematics!!! This is very exciting because 55% is so much higher than 10%, meaning that the machine did learn a good deal about digits during its first five minutes at school.\n",
                "\n",
                "However, note that on the training set the machine, or better, the weight matrix performs much better, above 80%. This is a classic case of overfitting, mainly due to the small sized training set that we provided. So we leave the reader with some questions to think about:\n",
                "\n",
                "- How can you fix this overfitting? \n",
                "- Can you speed up the calculations to allow for bigger size traning sets (would dropouts make sense here)?\n",
                "- Can you improve the model by allowing $h$ and $-h$ learning steps?\n",
                "\n",
                "\n",
                "Have fun!\n",
                "\n",
                "\n",
                "---\n",
                "Author: Lorenzo Toniazzi\n",
                "Github: ltoniazzi",
            ],
        },
        {
            "cell_type": "markdown",
            "id": "0bf7ac0e-cd95-47a8-8096-9832fd6b496c",
            "metadata": {},
            "source": [
                "### Future additions\n",
                "\n",
                "- Comparable tensorflow model.\n",
                "- Speed up this code with JAX.",
            ],
        },
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3",
        },
        "language_info": {
            "codemirror_mode": {"name": "ipython", "version": 3},
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.6",
        },
    },
    "nbformat": 4,
    "nbformat_minor": 5,
}
